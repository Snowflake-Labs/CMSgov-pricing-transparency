import sys ,os ,io ,json ,logging
import pandas as pd
from snowflake.snowpark.session import Session
import snowflake.snowpark.functions as F
import _snowflake

logger = logging.getLogger("innetwork_rates_segment_dagbuilder_sp")

BATCH_SIZE = 5000
IN_NETWORK_RATES_SEGHDR_TBL = 'in_network_rates_segment_header'

def create_root_task_and_fh_loader(p_session: Session ,p_root_task_name: str ,p_stage_path: str ,p_datafile: str): 
    logger.info(f'Creating the root task ddl ...')

    sql_stmts = [
        f'alter task if exists {p_root_task_name} suspend;'
        ,f'''
            create or replace task {p_root_task_name}
                schedule = 'using cron 30 2 L 6 * UTC'
                comment = 'DAG to load data for file: {p_datafile}'
                as
                select current_timestamp;
        '''
        # ,f'''
        # create or replace task fh_{p_root_task_name}
        #     user_task_managed_initial_warehouse_size = 'XSMALL'
        #     comment = 'file header data ingestor for file: {p_datafile}'
        #     after {p_root_task_name} 
        #     as 
        #     call innetwork_rates_fileheader_ingestor_sp('{p_stage_path}','{p_datafile}');
        # '''
        # ,f'alter task if exists fh_{p_root_task_name} resume;'
    ]
    for stmt in sql_stmts:
        p_session.sql(stmt).collect()


def iterate_define_ddl(p_session: Session ,p_root_task_name: str 
    ,p_approx_batch_size: int ,p_stage_path: str ,p_datafile: str): 
    logger.info(f'Creating the task ddl ...')

    # DDL task creation
    task_ddls = []
    df =(p_session.table(IN_NETWORK_RATES_SEGHDR_TBL)
            .select('HEADER_ID_HASH' ,'HEADER_ID' ,'FILE')
            .filter(F.col('DATA_FILE') == F.lit(p_datafile))
            .to_pandas()
        )
    for index, row in df.iterrows():
        header_id_hash = row['HEADER_ID_HASH']
        task_name = f'tsk_{header_id_hash}'.replace('-','_')
        # user_task_managed_initial_warehouse_size = 'XSMALL'
        # after {p_root_task_name}
        ddl = f'''
            create or replace task {task_name}
                WAREHOUSE = dev_pctransperancy_demo_wh
                comment = 'negotiated_rates segment[{row['HEADER_ID']}] data ingestor for file: {p_datafile}'
                schedule = 'using cron 30 2 L 6 * UTC'
                as
                call innetwork_rates_segments_ingestor_sp( 
                    {p_approx_batch_size} ,'{p_stage_path}','{p_datafile}'
                    ,'negotiated_rates'
                    ,'{row['HEADER_ID']}');
            '''
        task_ddls.append( (task_name ,ddl) )
        
    
    return task_ddls

def main(p_session: Session ,p_approx_batch_size: int ,p_stage_path: str  ,p_datafile: str):
    ret = {}
    ret['data_file'] = p_datafile

    root_task_name = f'''DAG_INNETWORK_LOAD_{p_datafile.replace('-','_').replace('.zip','')}'''

    p_session.sql(f'alter task if exists {root_task_name} suspend;').collect()
    create_root_task_and_fh_loader(p_session ,root_task_name ,p_stage_path ,p_datafile)

    task_def_errors = []
    task_ddls = iterate_define_ddl(p_session ,root_task_name ,p_approx_batch_size ,p_stage_path ,p_datafile)
    idx = 0
    for task_name ,tddl in task_ddls:
        try:
            sql_stmt = f'alter task if exists {task_name} suspend;'
            p_session.sql(sql_stmt).collect()
            
            p_session.sql(tddl).collect()

            # sql_stmt = f'alter task if exists {task_name} resume;'
            # p_session.sql(sql_stmt).collect()

            # sql_stmt = f'execute task {task_name};'
            # p_session.sql(sql_stmt).collect()

            # if idx >= 75:
            #     break

        except Exception as e: 
            task_def_errors.append(task_name)
            logger.info(f"Not able to define task: {task_name}")
            ret['task_ddl_exception'] = str(e)
            ret['task_ddl'] = tddl
            ret['task_ddl_idx'] = idx
            ret['failed_task'] = task_name
            break
        idx += 1
        
    # p_session.sql(f'alter task if exists {root_task_name} resume;').collect()
           
    # ret['task_errored'] = task_def_errors    
    ret['root_task_name'] = task_ddls

    # -- TODO
    # execute root task

    ret['root_task_name'] = root_task_name
    ret['no_of_subtasks_created'] = len(task_ddls)
    
    ret['status'] = True
    return ret